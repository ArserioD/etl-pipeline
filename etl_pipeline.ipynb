{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af122cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read CSV file into a DataFrame for initial inspection\n",
    "df = pd.read_csv('userprofile.csv')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d409836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded data from C:\\Users\\MrDav\\userprofile.csv\n",
      "Data extraction successful. Data shape: (138, 19)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def extract_data(file_path):\n",
    "    \"\"\"\n",
    "    Reads the CSV file from the specified file path.\n",
    "    \n",
    "    Parameters:\n",
    "        file_path (str): The absolute or relative path to the CSV file.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame or None: The loaded DataFrame if successful, or None if an error occurs.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(f\"Successfully loaded data from {file_path}\")\n",
    "        return df\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: {e}. Please check and ensure the CSV file exists at: {file_path}\")\n",
    "        return None\n",
    "\n",
    "# Specify the file path. Update this path if your file is stored elsewhere.\n",
    "file_path = r'C:\\Users\\MrDav\\userprofile.csv'\n",
    "\n",
    "# Extract the data\n",
    "df = extract_data(file_path)\n",
    "\n",
    "if df is not None:\n",
    "    print(\"Data extraction successful. Data shape:\", df.shape)\n",
    "else:\n",
    "    print(\"Data extraction failed. Verify your file path and CSV file placement.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f2fec6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation complete. New columns include: ['userID', 'latitude', 'longitude', 'smoker', 'drink_level', 'dress_preference', 'ambience', 'transport', 'marital_status', 'hijos', 'birth_year', 'interest', 'personality', 'religion', 'activity', 'color', 'weight', 'budget', 'height', 'age']\n",
      "Transformed data preview:\n",
      "  userID   latitude   longitude  smoker     drink_level dress_preference  \\\n",
      "0  U1001  22.139997 -100.978803   False      abstemious         informal   \n",
      "1  U1002  22.150087 -100.983325   False      abstemious         informal   \n",
      "2  U1003  22.119847 -100.946527   False  social drinker           formal   \n",
      "3  U1004  18.867000  -99.183000   False      abstemious         informal   \n",
      "4  U1005  22.183477 -100.959891   False      abstemious    no preference   \n",
      "\n",
      "  ambience transport marital_status        hijos  birth_year    interest  \\\n",
      "0   family   on foot         single  independent        1989     variety   \n",
      "1   family    public         single  independent        1990  technology   \n",
      "2   family    public         single  independent        1989        none   \n",
      "3   family    public         single  independent        1940     variety   \n",
      "4   family    public         single  independent        1992        none   \n",
      "\n",
      "           personality  religion      activity  color  weight  budget  height  \\\n",
      "0    thrifty-protector      none       student  black      69  medium    1.77   \n",
      "1  hunter-ostentatious  Catholic       student    red      40     low    1.87   \n",
      "2          hard-worker  Catholic       student   blue      60     low    1.69   \n",
      "3          hard-worker      none  professional  green      44  medium    1.53   \n",
      "4    thrifty-protector  Catholic       student  black      65  medium    1.69   \n",
      "\n",
      "   age  \n",
      "0   36  \n",
      "1   35  \n",
      "2   36  \n",
      "3   85  \n",
      "4   33  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def transform_data(df):\n",
    "    \"\"\"\n",
    "    Cleans and transforms the extracted DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): Raw DataFrame extracted from CSV.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: Cleaned and transformed DataFrame.\n",
    "    \"\"\"\n",
    "    # Replace placeholder \"?\" with NaN\n",
    "    df = df.replace('?', np.nan)\n",
    "    \n",
    "    # Convert columns to appropriate types\n",
    "    # Convert birth_year, weight, and height to numeric (if necessary)\n",
    "    df['birth_year'] = pd.to_numeric(df['birth_year'], errors='coerce')\n",
    "    df['weight'] = pd.to_numeric(df['weight'], errors='coerce')\n",
    "    df['height'] = pd.to_numeric(df['height'], errors='coerce')\n",
    "    \n",
    "    # Convert boolean fields if stored as string - example for 'smoker'\n",
    "    # (Assume that if the value is \"true\" or has boolean indication, then convert)\n",
    "    df['smoker'] = df['smoker'].astype(str).str.lower().apply(lambda x: True if x == 'true' else False)\n",
    "    \n",
    "    # Add derived column: Calculate age based on the current year (for demonstration)\n",
    "    current_year = 2025  # Use a fixed current year or import datetime for dynamic value\n",
    "    df['age'] = current_year - df['birth_year']\n",
    "    \n",
    "    # Other transformation steps: standardize text fields, create segmentation columns, etc.\n",
    "    # For instance, trim spaces or convert categorical fields to lowercase:\n",
    "    for col in ['drink_level', 'dress_preference', 'ambience', 'transport']:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].str.lower().str.strip()\n",
    "    \n",
    "    print(\"Transformation complete. New columns include:\", df.columns.tolist())\n",
    "    return df\n",
    "\n",
    "if df is not None:\n",
    "    df_transformed = transform_data(df)\n",
    "    print(\"Transformed data preview:\")\n",
    "    print(df_transformed.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22a3d4fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully loaded to C:\\Users\\MrDav\\userprofile_transformed.csv\n"
     ]
    }
   ],
   "source": [
    "def load_data(df, output_path):\n",
    "    \"\"\"\n",
    "    Loads the DataFrame to the specified output path.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): Cleaned and transformed DataFrame.\n",
    "        output_path (str): Path to store the output CSV file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df.to_csv(output_path, index=False)\n",
    "        print(f\"Data successfully loaded to {output_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error while saving the file: {e}\")\n",
    "\n",
    "# Specify the output path (you can use an absolute path or store it in the working directory)\n",
    "output_path = r'C:\\Users\\MrDav\\userprofile_transformed.csv'\n",
    "load_data(df_transformed, output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9b7a634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully loaded into table 'UserProfiles' in C:\\Users\\MrDav\\etl_demo.db\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "def load_data_to_sqlite(df, db_path, table_name):\n",
    "    \"\"\"\n",
    "    Loads the DataFrame into a SQLite database.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): Cleaned and transformed DataFrame.\n",
    "        db_path (str): Path to the SQLite database file.\n",
    "        table_name (str): Name of the table to create/replace.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        conn = sqlite3.connect(db_path)\n",
    "        df.to_sql(table_name, conn, if_exists='replace', index=False)\n",
    "        conn.close()\n",
    "        print(f\"Data successfully loaded into table '{table_name}' in {db_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data into SQLite: {e}\")\n",
    "\n",
    "# Specify database file (or use an in-memory database)\n",
    "db_path = r'C:\\Users\\MrDav\\etl_demo.db'\n",
    "table_name = 'UserProfiles'\n",
    "load_data_to_sqlite(df_transformed, db_path, table_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183f9e36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
